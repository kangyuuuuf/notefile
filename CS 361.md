# CS 361 Prob & Stat for Computer Sci

[The poll link](https://pollev.com/hongyeliu713) / [The course link](https://canvas.illinois.edu/courses/24920) / 

#### Data types

**Categorical:** discreet, not have the order (the genre of music)

**Ordinal:** ordered, discreet (the level of school)

**Continuous:** continuous data (temperature)

#### Simple Visualization of Data

**General principles:** must not mislead or distort; Aesthetically pleasing; Clear, convincing; Show message

Bar graph & Histogram

####  Summarizing 1-D continuous data

For a data set $\{x\}$ or annotated as $\{x_i\}$, we summarize with:

**Location Parameters:** mean, median, mode

**Scale Parameters:** $std$, $variance = std^2$, interquartile range

##### Mean

$$
mean(\{x_i\}) = \frac{1}{N}\sum^N_{i=1}x_i \\
mean(\{k \cdot x_i\}) = k \cdot mean(\{x_i\}) \\
mean(\{x_i + c\}) = mean(\{x_i\}) +c
$$

The mean **minimizes** the sum of the squared distance from any real value.
$$
arg\min_\mu (\sum^N_{i=1}(x_i-\mu)^2) = mean(\{x_i\})
$$

##### Standard Deviation($\sigma$)

$$
std(\{x_i\}) = \sqrt{\frac{1}{N} \sum^N_{i=1}(x_i-mean(\{x_i\}))^2} = mean(\{(x_i-mean(\{x_i\}))^2\}) \\
 std(\{k \cdot x_i\})= |k|\cdot std(\{x_i\})\\
 std(\{ x_i + c\})= std(\{x_i\})
$$

At most $\frac{N}{k^2}$ items are $k$ standard deviations away from the mean.

##### Variance($\sigma^2$)

$$
var(\{x_i\}) = \frac{1}{N} \sum^N_{i=1}(x_i-mean(\{x_i\}))^2
$$

#### Interquartile range

$$
iqr(\{k \cdot x_i\}) = |k|\cdot iqr(\{x_i\}) \\

iqr(\{x_i+c\}) = iqr(\{x_i\})
$$



##### Normalized Data

The mean tells where the data set is and the standard deviation tells how spread out it is. If we are interested only in comparing the shape, we could define:
$$
\hat x_i = \frac{x_i-mean(\{x_i\})}{std(\{x_i\})}
$$
And we say $\{\hat x_i\}$ is in standard coordinates.

##### Median

Same feature as mean



#### Permutation

Given a finite number of distinct elements.

A permutation is a particular way of ordering them, and Number of ways of ordering n distinct elements: $n!$

#### K-Permutation

Given a finite number of distinct elements.

K-permutation is a particular way of ordering them with k elements, and Number of ways of ordering k distinct elements with n overall elements: $\frac{n!}{(n-k)!}$

#### Conbinations 

A combination is a choice of k obhjects  out of n distict object $0\le k \le n$, no order needed for the choosen stuff. n choose k can be denoted as $\frac{n!}{k!(n-k)!}$

Note:
$$
(^{n}_k) = (^{\  \ n}_{n-k}) \\
n(^{n-1}_{k-1}) = k(^n_k)
$$


#### Partitions

Given n distinct objects, when we divid them into r disjoint groups.

The total number of partitions is 
$$
\frac{n!}{n_1!n_2! \dots n_r!}
$$

#### Tails and Skews

<img src="CS%20361.assets/image-20220830112831805.png" alt="image-20220830112831805" style="zoom:50%;" />



#### Correlation seen from scatter plots

<img src="CS%20361.assets/image-20220830113139819.png" alt="image-20220830113139819" style="zoom:50%;" />

#### Correlation Coefficient

$$
corr(\{x_i,y_i\}) = \frac{1}{N}\sum_{i=1}^n \hat{x_i} \hat{y_i}
$$

where $\hat{x_i} = \frac{x_i - mean(\{x_i\})}{std(\{x_i\})}$ and $\hat{y_i} = \frac{y_i - mean(\{y_i\})}{std(\{y_i\})}$ 

Notice that $corr(\{x_i,y_i\})=corr(\{y_i,x_i\})$ which is symmetric. Translating the data does not change the correlation coefficient.

Notice that scaling the data may change the sign of the correlation coefficient
$$
corr(\{ax_i+b,cy_i+d\}) = sign(ac) corr(\{x_i,y_i\}) 
$$
The correlation coefficient is bounded within [-1,1]. When the plot shows a straight line, the coefficient is (1,-1). However, we cannot calculate the coefficient if the slope of the line is zero.

We can rewrite the formula into
$$
corr(\{x_i,y_i\}) = \sum_{i=1}^n \frac{\hat{x_i}}{\sqrt N} \frac{\hat{y_i}}{\sqrt N} = v_1^Tv_2 = |v_1||v_2|\cos(\theta)
$$
Since the norm of 2 vector is 1 and cos function is bounded between -1 and 1. Then, it is bounded within [-1,1].

We have the equation.
$$
y^p = rx^p
$$


#### Outcome

An outcome A is a possible result of a random repeatable experiment.

#### Sample space

The sample space, $\Omega$, is the set of all possible mutually exclusive outcomes associated with the experiment. 

#### Event

An event $E$ is a subset of the sample space $\Omega$. 

#### Frequency Interpretation of Probability.

Given an experiment with an outcome A, we can calculate the probability of $A$ by repeating the experiment over and over
$$
P(A) = \lim_{N\rarr \infin} \frac{\text{number of time  $A$ occurs}}{N}
$$
So, $0 \le P(A) \le 1$ and $\sum_{A_{i}\in\Omega} = 1$

If the outcomes have equal probability,
$$
P(E) = \frac{\text{number of outcomes in $E$}}{\text{total number of outcomes in } \Omega}
$$


#### Axiomatic Definition of Probability

A probability function is any function P that maps sets to real number and satisfies the following three axioms:

1. The probability of any event E is non-negative: $P(E) \ge 0$
2. Every experiment has an outcome: $P(\Omega) = 1$

3. The probability of disjoint events is additive: $P(E_1 \cup E_2 \dots \cup E_N) = \sum^N_{i=1}P(E_I)$ if $E_i \cap E_j = \empty$ for all $i \ne j$.

#### Properties of probability

The compliment: $P(E^c )= 1 - P(E)$

The difference: $P(E_1-E_2) = P(E_1) -P(E_1 \cap E_2)$

The Union: $P(E_1 \cup E_2) = P(E_1)+P(E_2) - P(E_1\cap E_2)$ 

### Conditional Probability

$$
P(A|B) = \frac{P(A \cap B)}{P(B)} \text{ where }P(B) \neq 0
$$

Then, we have
$$
P(A\cap B) = P(A|B)P(B)
$$
Combine together, we have the Bayes rule
$$
P(A|B) = \frac{P(B|A)P(A)}{P(B)}
$$
Note
$$
P(A\cap B) = P(B \cap A)  \Longrightarrow P(B|A)P(A) = P(A|B) P(B)
$$

### Bayes Rule, Inpendence

#### Total Probability

Lest events $A_1,A_2, \dots, A_n$ be a partition of the sample space( i.e. $A_i $ are disjoint events and their union is the sample space), wth $P(A_i) >0$ for all $i$. Then, 
$$
P(B) = \sum^n _i P(A_i)P(B|A_i)
$$


#### Bayes Rule Using Total Prob

$$
P(A_j | B) = \frac{P(B|A_j)P(A)}{P(B)} = \frac{P(B|A_j)P(A)}{\sum_j  P(B|A_j)P(A_j)}
$$

### Random Variable

The values of a random variable can be either discrete, continuous or mixed. The range of a discrete random variable is a countable set of real numbers. 

#### Three important facts of Random Variables

- Randome variables have probability 
- Rabdom variables can be conditioned on events or other random variables
- Random variables have averages.

**Probability function** for a random variable $X$ is $P(X = x_0) = \sum P(w_i)$

$P(X= x)$ is called the **probability distribution** for all possible $x$.

$P(X=x) $ is also denoted as $P(x)$ or $p(x)$.

$P(X = x) \ge 0$ for all values that $X$ can take, and is 0 everywhere else

The sum of the probability distribution is 1

#### Cumulative distribution

$P(X \le x)$ is called the cumulative distribution function of $X$

$P(X \le x)$ is also denoted as $f(x)$

$P(X \le x)$ is a non-decreasing funciton of $x$

### PDF and Expected Value

The conditional probability distribution of $X$ given $Y$ is
$$
P(x|y) = \frac{P(x,y)}{p(y)} \qquad P(y) \ne 0
$$
Note $P(x,y) = P(X=x \cap Y =y)$.

The joint probability distribution of two random variables $X$ and $Y$ is $P(\{X=x\} \cap \{Y=y\})$



#### Marginal from Joint distri.

We can recover the individual probability distributions from the joint probability distribution
$$
P(x) = \sum_yP(x,y)
$$


The sum of the joint probability distribution
$$
\sum_y \sum_x P(x,y) =1
$$
Random varibale $X$ and $Y$ are independent if
$$
P(x,y) = P(x) P(y) \text{ for all $x$ and $y$}
$$
If X and Y are disjoint, then they cannot be independent.

#### Expected Value



The expected value (or expectation) of a random variable $X$ is
$$
E[X] = \sum_x xP(x)
$$


##### Linearity

$E[X] = \sum _i x_ip_X(x_i)$

$E[kx]= kE[x]$

$E[x+y] = E[x]+E[y]$

$E[kX+c] = kE[X] +c$

#### Variance and standard deviation

The variance of a random variable $X$ is
$$
var[X] = E [(X- E[X])^2]
$$
It is the same as:
$$
var[X] = E[X^2] - E{[X]^2}
$$

For random varibale $X$ and constant $k$ $var[kX] = k^2 var[X]$.

#### Multiple Random Variables

##### Join PMF

- $p_{xy}(x_i,y_j) = P(X = x_i \& Y =y_j)$

##### Marginal probability can be derived from the joint PMF

- $P_x(x_i) = \Sigma_jp_{XY}(x_i,y_j)$
- $P_y(y_j) = \Sigma_ip_{XY}(x_i,y_j)$

##### Conditional probability mass function

- $p_{X|Y}(x_i|y_j) = P(X=x_i |Y = y_j) = \frac{p_{X|Y}(x_i,y_j)}{p_Y(y_j)}$

#### Independence

- $p_{XY}(x_i,y_j) = p_X(x_i)p_Y(y_j) \iff P(X \in B)P(Y\in C)$

##### Variance

$Var(X) = E[(X-E[X])^2] = E[X^2] - E[X]^2$

#### Expected value of a function of $X$

If $f$ is a function of a random variable $X$, then $Y = f(x)$ is a random variable too.

The expected value of $Y = f(X)$ is $E[Y] = E[f(x)] = \sum_x f(x) P(x)$

$E[f(x,y)]=\sum_x \sum_yf(x,y)p(x,y)$  

### Weak Law of large Number

#### Covariance

The convariance of random 2 $X$ and $Y$ is  $cov(X,Y) = E[(X -E(X))(Y-E[Y])]$ 

Note that $cov(X,X) = E[(X-E[x])^2] = var[X]$

Then, we can get a neater expression for covariance ( similar derivation as for variance)
$$
cov(X,Y) = E[XY] - E[X]E[Y] = \sum \sum E[XY] - E[X]E[Y]
$$


The correlation coefficient is normalized covariance. The correlation coefficient is 
$$
corr(X,Y) = \frac{cov(X,Y)}{\sigma_x\sigma_y} = \frac{E[XY]-E[X]E[Y]}{\sigma_x\sigma_y}
$$
Note that independence indicates correlation  = 0. However, correlation = 0 do not indicate independence
$$
var[X+Y] = var[X] + var[Y] + 2 cov(X,Y)
$$
When the correlation coefficient is 0, then $E[XY] -E[X] [Y] = 0 \Longrightarrow E[XY] = E[X]E[Y]$. This is a necessary property of independence of random variables. Or we can say,

Independence $\implies$ Covariance = 0 and Covariance = 0 $\centernot\Longrightarrow$ Independence

If  correlation = 0, then
$$
E[XY] = E[X] E[Y]\\
cov(X,Y) = 0 \\ 
var[X+y] = var[X] +var[Y]
$$

Note if $cov(X,Y) = 0$, we have
$$
E[X+Y] = E[X] + E[Y] \qquad \text{always true}
\\V[X+Y] = V[X]+V[Y] + 2cov(X,Y) \qquad \text{when } cov(X,Y) = 0
\\E[XY] = E[X]E[Y]  \Longleftarrow E[XY]-E[X]E[Y] = cov(X,Y) = 0
\\Corr[X,Y] = 0 \Longleftarrow corr[X,Y] = \frac{cov(X,Y)}{\sigma_X \sigma_Y} = 0
$$
However, we do not have $P(X=x,Y=y) = P(X=x)P(Y=y)$ since $cov(X,Y) = 0$ do not imply independence 

#### Markov’s inequality

For any random variable $X^*$ that only takes $x^* \ge 0$ and constant $a >0$
$$
P(X^* \ge a) \le \frac{E[X^*]}{a}
$$

#### Chebyshev’s inequality

For **any** random variable $X$ and constant $a > 0$
$$
P(|X-E[X]| \ge a ) \le \frac{var[X]}{a^2}
$$
If we let $a = k \sigma$ where $\sigma = std[x]$
$$
P(|X-E[X]| \ge k \sigma ) \le  \frac{1}{k^2}
$$
In words, the probability that $X$ is greater than $k$ standard deviation away from the mean is small.

#### Sample mean and IID samples

We define the sample mean $\bar{X}$ to be the average of $N$ random variables $X_1, \dots, X_N$. If $X_1, \dots, X_N$ are **independent** and have **identical** probability function $P(X)$, then the numbers randomly generated from them are called **IID samples**. The **sample mean** is a random variable.

Assume we have a set of **IID samples** from $N$ random variables $X_1, \dots, X_N$ that have probability function $P(X)$, we use $\bar X$ to denote the sample mean of these **IID samples**
$$
\bar X = \frac{\sum_{i=1}^N X_i}{N}
$$
By linearity of expected value
$$
E[\bar X] = E[\frac{\sum_{i=1}^N X_i}{N}] = \frac{1}{N} \sum_{i=1}^N E[X_i] = E[X]
$$
By the scaling of variance
$$
var[\bar X] = var[\frac{1}{N} \sum_{i=1}^N X_i] = \frac{1}{N^2} var[\sum_{i=1}^N X_i]
$$
Given each $X_i$ has identical $P(x), var[X_i] = var[X]$
$$
var[\bar X] = \frac{var[X]}{N}
$$

#### Weak law of large numbers

Given a random variable $X$ with finite variance, probability distribution function $P(X)$ and the sample mean $\bar X$ of size $N$

For any positive number $\epsilon > 0$ 
$$
\lim_{N \rarr \infin} P(|\bar X - E[X]| \ge \epsilon) = 0
$$
That is: the value of the mean of **IID** samples is very close with a high probability to the expected value of the population when the sample size is very large.

#### Sum of IID sample

![image-20221109215001115](CS%20361.assets/image-20221109215001115.png)

### Discrete Distributions

#### Probability Density Function

For a continuous random variable $X$, the probability that $X= x$ is essentially zero for all (or most) x, so we cannot define $P(X =x)$. Instead, we define the probability density function (pdf) over an infinitesimally small interval $dx$, $p(x)dx = P(X \in [x,x+dx])$. For $a<b$
$$
\int_a^b p(x) dx = P(X \in [a,b])
$$
$p(x)$ **resembels** the probability function of discrete random variables in that 

- $p(x) \ge 0$ for all $x$
- The probability of $X$ taking all possible values is 1.

$p(x)$ differs from the probability distribution function for a discrete random variable in that

- $p(x)$ is not the probability that $X=x$
- $p(x)$ can exceed 1

#### Expectation of Continuous Variables

Expected value of a continuous random variable $X$
$$
E[X] = \int_{-\infin}^{\infin} xp(x) dx
$$
Expected value of function of continuous random variable $Y= f(X)$
$$
E[Y] = E[f(x)] = \int_{-\infin}^{\infin} f(x)p(x) dx
$$
The linearity of the expected value is true for continuous random variables. And the other properties that we derived for variance and covariance also hold for continuous random variables.

#### Distributions

##### Bernoulli distribution

A random variable $X$ is **Bernoulli** if it takes on two values 0 and 1 such that $P(X= 1) = p, P(X= 0) = 1-p$.

Then, $E[x] = p$, $var[X] = p(1-p)$.

Examples: tossing a biased coin; making a free throw; rolling a six-sided die and checking if it show 6

##### Binomial Distribution

A discrete random variable $X$ is binomial if 
$$
P(X = k) = \binom{N}{k}p^k(1-p)^{N-k} \qquad \text{for integer }0\le k\le N
$$
with $E[X] = Np$ and $var[X] = Np(1-p)$

Examples: If we roll a six-sided die N times, how many sixes will we see; What is the sum of N independent and identically distributed Bernoulli trials?

##### Geometric Distribution

A discrete random variable $X$ is geometric if
$$
P(X=k) = (1-p)^{k-1} p \qquad k\ge 1
$$
With $E[X] = \frac{1}{p}$ and $var[X] = \frac{1-p}{p^2}$

Examples: How many rolls of a six-sided die will it take to see the first 6? How many Bernoulli trials must be done before the first 1? How many experiments needed to have the first success?

##### Multinomial Distribution

A discrete r.v. X is multinomial if 
$$
P(X_1=n_1, \dots , X_k=n_k) = \frac{N!}{n_1!n_2!\dots n_k!}p_1^{n_1}p_2^{n_2}\dots p_k^{n_k}
$$
Where $N = n_1+n_2 + \dots + n_k$

##### Poisson Distribution

A discrete random variable $X$ is called Poisson with intensity $\lambda(\lambda >0)$ if 
$$
P(X =k) = \frac{e^{-\lambda}\lambda^k}{k!} \qquad \text{for integer } k \ge 0
$$
$\lambda$ is the average rate of the event's occurrence.

With $E[X] = \lambda$ and $var[X] = \lambda$.

##### Continuous Uniform Distribution

A continuous random variables $X$ is uniform if 
$$
p(x) = \begin{cases}
\frac{1}{b-a} \qquad x\in [a,b]\\
0 \qquad otherwise
\end{cases}
$$
With $E[X] = \frac{a+b}{2}$ and $var[X] = \frac{(b-a)^2}{2}$

##### Exponential Distribution

A continuous random variables $X$ is called exponential distribution if 
$$
p(x) = \lambda e^{-\lambda x}\text{ for }x \ge 0
$$
With $E[X] =\frac{1}{\lambda}$ and $var[X] = \frac{1}{\lambda}$.

## CLT and Sample Mean

#### Normal (Gaussian) Distribution

The most famous continuous random variable distribution. The probability density is
$$
\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}
$$
With $E[X] = \mu$ and $var[X] = \sigma^2$

#### Standard Normal Distribution

A continuous random variable $X$ is standard normal if
$$
p(x) = \frac{1}{\sqrt{2\pi}}e^{-\frac{(x)^2}{2}}
$$
With $E[X] = 0$ and $var[X] = 1$

#### Central Limit Theorem(CLT)

The distribution of the sum of $N$ independent identical (IID) random variables tends toward a normal distribution as $N \longrightarrow \infin$ 

### Confidence Interval

#### Sample

The sample is a random subset of the popultiton and is denoted as $\{x\}$, where sampling is done with **replacement**

-   The sample size $N$ is assumed to be much less than popultion size $N_P$
-   The sample mean of a population is $X^{(N)}$ and is a random variable

#### Sample Mean - Sample

-   The sample is a random subset of the population denoted as $\{x\}$.
-   Sampling is done with replacement: sample size $N << N_p$
-   Sample mean of a population is a random variable: $X^{(N)}$.

#### Expectation of Sample Mean

![image-20221016174443614](CS%20361.assets/image-20221016174443614.png)

#### Sample mean of a population 

The sample mean is the average of **IID** samples
$$
X^{(N)} = \frac{1}{N}(X_1+X_2+\dots + X_N) = mean(\{X\})
$$
By linearity of the expectation and the fact the sample items are identicially drawn from thr same population with replacement:
$$
E[X^{(N)}] = \frac{1}{N}(E[X^{(1)}]+E[X^{(1)}]+\dots + E[X^{(1)}]) = E[X^{(1)}]
$$
Since each sample is frawn uniformly from the population $E[X^{(1)}] = popmean(\{X\})$. Therefore, $E[X^{(N)}] = popmean(\{X\})$. We say that $X^{(N)}$ is an unbiased estimator of the population mean.

We can also rewrite another result from the lecture on the weak law of large numbers
$$
var[X^{(N)}] = \frac{popvar(\{X\})}{N}
$$
The standard deviation of tje sample mean
$$
std[X^{(N)}] = \frac{popstd(\{X\})}{\sqrt{N}}
$$

<img src="CS%20361.assets/image-20221016174608137.png" alt="image-20221016174608137" style="zoom:50%;" />

#### Stderr

The unbiased estimate of $popst(\{X\})$ is defined as 
$$
stdunbiased(\{x\}) = \sqrt{\frac{1}{N-1} \sum_{x_i \in sample} (x_i - mean(\{x\}))^2}
$$
So the standard error is an estimate of  $std[X^{(N)}]$
$$
\frac{popstd(\{X\})}{\sqrt{N}} \approxeq \frac{stdunbiased(\{x\})}{\sqrt{N}} = stderr(\{x\})
$$

#### Distribution of $X^{(N)}$

If $N \longrightarrow \infin$, then $X^{(N)}\sim Normal(\mu, \sigma)$ where $\mu = E[X^{(N)}]$ and $\sigma = std[X^{(N)}]$

If $X^{(1)}$ is from a Normal-like population, $T = \frac{mean(\{x\})-popmean}{stderr} \sim t \text{ distribution with DOF } N-1$ 

#### Expected value of one random sample

Since each sample is drawn uniformly from the population
$$
E[X^{(1)}] = popmean(\{X\}) \implies E[X^{(N)}] = popmean(\{X\})
$$

#### Interpreting the standard error

**Sample mean** is a random variable and has its own probability distribution, stderr is an estimate of sample mean’s standard deviation.

When $N$ is very large, according to the Central Limit theorem, sample mean is approaching a normal distribution with 
$$
\mu = popmean(\set{X}) \text{ and } \sigma = \frac{popsd(\set X)}{\sqrt N} \approx stderr(\set x)
$$
where $stderr(\set x) = \frac{std unbiased(\set x)}{\sqrt N}$

#### CI when $N <30$

If the sample size $N< 30$, we should use t-distribution with its parameter (DOF) set to $N-1$ 

#### Sample Statistic

A **statistic** is a function of dataset. For example, the mean or median of a dataset is a statistic.

**Sample statistic** is a statistic of the data set than is formed by the realized sample. For example, the realized sample mean.

#### Bootstrap

Bootstrap is a method to construct confidence interval for any* sample statistics using resampling of the sample data set. Bootstrapping is essentially uniform random sampling with replacement on the sample of size $N$.

<img src="CS%20361.assets/image-20221012124758567.png" alt="image-20221012124758567" style="zoom:50%;" />

<img src="CS%20361.assets/image-20221012124857908.png" alt="image-20221012124857908" style="zoom:50%;" />

#### Error in Bootstrapping

The distribution simulated from bootstrapping is called empirical distribution. It is not the true population distribution. There is a statistical error.

The number of bootstrapping replicates may not be enough. There is a numerical error.

When the statistic is not a well-behaving one, such as maximum or minimum of a data set, the bootstrap method may fail to simulate the true distribution.

## Hypothesis Tests

Assume the hypothesis $H_0$ is true, define a statistic for the test
$$
x = \frac{sample\ mean - hypothesized\ value}{standard \ error}
$$
Since $N > 30$, we assume $x$ comes from a standard normal. So, the fraction of “less extreme” statistic is 
$$
f = \frac{1}{\sqrt{2\pi}}\int_{-|x|}^{|x|} exp(-\frac{u^2}{2})du
$$
It is conventional to report the p-value of a hypothesis test
$$
p = 1 - f
$$
<img src="CS%20361.assets/image-20221016175832700.png" alt="image-20221016175832700" style="zoom:50%;" />

#### Chi-square distribution

If $Z'_i$ are independent variables of standard normal distribution,
$$
X = Z^2_1+ Z^2_2 + \dots + Z^2_m = \sum_{i=1}^m Z^2_i
$$
has a Chi-square distribution with degree of freedom $m$, $X \sim \chi^2(m)$

We can test the goodness of fit for a model using a statistic $C$ against this distribution where
$$
C = \sum^m_{i =1} \frac{(f_o(\epsilon_i) - f_t(\epsilon_i))^2}{f_t(\epsilon_i)}
$$

#### Degree of Chi-Square

The degree of freedom for the chi-square distribution for a $r$ by $c$ table is
$$
(r-1)\times(c-1) \quad where \ r > 1 \ and\ c>1
$$
<img src="CS%20361.assets/image-20221016180932082.png" alt="image-20221016180932082" style="zoom:50%;" />

## Maximum likelihood estimation

<img src="CS%20361.assets/image-20221016181030517.png" alt="image-20221016181030517" style="zoom:50%;" />

We write the probability of seeing the data $D$ given parameter $\theta$
$$
L(\theta) = P(D|\theta)
$$
The likelihood function $L(\theta)$ is not a probability distribution.

The maximum likelihood estimate (MLE) of $\theta$ is 
$$
\hat \theta = arg\max_\theta L(\theta)
$$


#### MLE with data from IID trials

If the dataset $D = \{x\}$ comes from IID trials
$$
L(\theta) = P(D|\theta) = \prod_{x_i \in D}P(x_i | \theta)
$$

#### Log-likelihood Function

We know that log is a strictly increasing fucntion
$$
\hat \theta = arg\max_\theta L(\theta) = arg\max_\theta \log L(\theta)
$$

$$
\log L(\theta) = \log P(D|\theta) = \log \prod_{x_i \in D}P(x_i | \theta) = \sum_{x_i \in D} \log P(x_i |\theta)
$$

The log-likelihood function is usually much easier to differentiate.

## Maximun Aposterior(MAP)

#### Beta Ditribution

A distribution is Beta distribution if it has the following pdf:
$$
P(\theta) = \cases{K(\alpha,\beta)\theta^{\alpha-1}(1-\theta)^{\beta -1} \\
0 \qquad otherwise}
$$

-   It is an expressive family of distributions
-   $Beta(\alpha = 1, \beta = 1)$ is uniform

#### The update of Bayesian posterior

Since the posterior is in the same family as the conjugate prior, the posterior can be used as a new prior if more data is observed

#### Table of conjugate prior for different likelihood functions

|           Likelihood           | Conjugate Prior |
| :----------------------------: | --------------- |
| Bernoulli, Geometric, Binomial | Beta distri.    |
|      Poisson, Exponential      | Gamma distri.   |
|  Normal with known $\sigma^2$  | Normal distri.  |

#### Multidimensional Data

#### Notation

-   Write $\set x$ for a dataset consisting of N $data$ items
-   Each item $x_i$ is a $d$-dimensional vector; column
-   Write $j$th compoinent of $x_i$ as $x_i^{(j)}$; row
-   Matrix for the data set $\set x$ is $d$ by $N$ dimension

##### Mean

Mean of $j$th component  = $\frac{\sum_i x_i^{(j)}}{N}$

Mean of $\set x$ as $mean(\set x) = \frac{\sum_i x_i}{N}$

#### [Covariance](#Covariance) 

Click to view the info.
$$
cov(\set x;j,k) = \frac{\sum_i (x_i^{(j)}- mean(\set{x_i^{(j)}}))(x_i^{(k)}- mean(\set{x_i^{(k)}}))}{N}
$$
The diagonal elements of the covariance matrix are just variances of the jth components.
$$
cov(\set x;j,j) = var(\set {x^{(j)}})
$$
The covariance matrix is Symmetric. And it is positive semi-definite that is all $\lambda_i \ge 0$

If we define $X_c$ as the mean centered matrix for dataset $\set x$, $ Covmat(\{x\})= \frac{X_cX_c^T}{N}$

The covariance is a $d \times d$ matrix.
$$
mean(\set x+c) = mean(\set x) + c \\
Covmat(\set x+c) = Covmat(\set x) \\
mean(\set{Ax}) = Amean(\set{x})  \\
Covmat(\set{Ax}) = ACovmat(\set x)A^T
$$

#### Diagonalization of a Symmetric Matirx

-   If $A$ is an $n\times n$ symmetric square matrix, the eigenvalues are real.
-   If the eigenvalues are also distinct, their eigenvectors are orthogonal
-   We can then scale the eigenvectors to unit length and place them into an orthogonal matrix $U = [u_1 \ u_2 \ \dots \ u_n]$ 
-   We can write the diagonal matrix $\Lambda = U^TAU$ such that the diagonal entries of $\Lambda$ are $\lambda_1,\lambda_2, \dots, \lambda_n$ in that order.

#### Principal Components

The columns if $U$ are the normalized eigenvectors of the $Covmat(\set x)$ and are called the principal components of the data$\set{x}$

<img src="CS%20361.assets/image-20221102220418733.png" alt="image-20221102220418733" style="zoom:50%;" />

<img src="CS%20361.assets/image-20221102220536305.png" alt="image-20221102220536305" style="zoom:50%;" />

<img src="CS%20361.assets/image-20221102220548737.png" alt="image-20221102220548737" style="zoom:50%;" />

#### Sample Covariance Matirx

In many statistical programs, the sample covariance matrix is defined to be 
$$
Covmat(\set m) = \frac{mm^T}{N-1}
$$
Similar to what happens to the unbiased standard deviation

#### The Mean Square Error of the Projection

The mean square error is the sum of the smallest d-s eigenvalues in $\Lambda$

#### <img src="CS%20361.assets/image-20221102221247518.png" alt="image-20221102221247518" style="zoom:50%;" /> Reconstruction the Data

Given the projected data $P_{d\times n}$ and $mean(\set x)$, we can approximately reconstruct the original data
$$
\hat D = Up + mean(\set x)
$$
<img src="CS%20361.assets/image-20221102221810778.png" alt="image-20221102221810778" style="zoom:50%;" />

#### End-to-end mean square error

<img src="CS%20361.assets/image-20221102222329365.png" alt="image-20221102222329365" style="zoom:50%;" />

#### Concept

-   Feature selecton should be conducted with domain knowledge.
-   Important feature may not show big variance 
-   The eigenvectors of covariance can have opposite signs and it won’t affect the reconstruct on 
-   The PCA analysis in some statistical program returns standard deviation instead of variance
-   PCA allows us to project data to the direction along which the data has the biggest variance
-   PCA allows us to compress data
-   PCA uses linear transformation to show patterns of data
-   PCA allows us to visualize data in lower dimensions

## Intro to Classification

#### Binary Classifiers

A binary classifier maps each feature vector to one of two classes.

#### Multiclass Classifiers

A multclass classifier maps each feature vector to one of three or more classes.

#### Nearest neighbors classifier 

<img src="CS%20361.assets/image-20221102224535587.png" alt="image-20221102224535587" style="zoom:50%;" />

In $k$-nearest neighbors, the classifier:

-   Looks at the $k$ nearest labeled feature vectors $x_i$
-   Assigns a label to $x$ based on a majority vote

In $(k,l)$-nearest neighbors, the classifier:

-   Looks at the $k$ nearest labeled feature vectors
-   Assigns a label to $x$ if at least $l$ of them agree on the classification 

## Classification

We use a confusion matrix to quantify the performance of a classifier. And the baseline accuracy of a c-classifier using 0-1 loss function is 1/c.

Assuming there are $c$ class: the class confusion matrix is $c \times c$. Under the 0-1 loss function accuracy:
$$
accuracy = \frac{\text{sum of diagonal terms}}{\text{sum of all terms}}
$$
And the baseline accuracy is $\frac{1}{c}$

#### Cross-Validation

If we don’t want to “waste” labeled data on validation, we can use cross-validation to see if our training methods is sound.

Split the labeled data into rraining and validation sets in multiple ways.

For each split(called a fold)

-   train a clasifier on the training set
-   Evaluate its accuracy on the validation set

Average the accuracy to evaluate the training methodology

#### Decision Tree

The object classification decision tree can classify objects into multiple classes using a sequence of simple tests. It will naturally grow into a tree.

#####  Traning a decision tree

1.  Choose a dimension/feature and a split
2.  Split the training Data into left-and right-child subsets $D_l$ and $D_r$
3.  Repeat the two steps above recursively on each child
4.  Stop the recursion based on some conditions
5.  Label the leaves with class labels

##### Choosing a split

An informative split makes the subsets more concentrated and reduces uncertainty about class labels

#### Quantifying uncertainty using entropy

We can measure uncertainty as the number of bits of information needed to distinguish between classes in a dataset (first introduced by Claude Shannon). Entropy(Shannon entropy) is the measure of uncertainty for a general distribution

If class $i$ contains a fraction $P(i)$ of the data, we need $\log_2\frac{1}{P(i)}$ bits for that class

The entropy H(D) of a dataset is defined as the weighted mean of entropy for every class:
$$
H(D) = \sum_{i=1}^c P(i) \log_2 \frac{1}{P(i)} = \sum^c_{i=1} -P(i) \log_2P(i)
$$

#### Information gain of a split

<img src="CS%20361.assets/image-20221125143857294.png" alt="image-20221125143857294" style="zoom:50%;" />

#### Choose a dimension and split

If there are $d$ dimensions, choose approximately $\sqrt d$ of them as candidates at random. For each candidate, find the split that maximizes the information gain. Choose the best overall dimension and split. Note that splitting can be generalized to categorical features for which there is no natural ordering of the data

#### Stop Growing of A decision Tree

Growing the tree too deep can lead to overfitting to the training data. Stop recursion on a data subset if any of the following occurs:

-   All items in the data subset are in the same class
-   The data subset becomes smaller than a predetermined size
-   A predetermined maximum tree depth has been reached.

#### Label the Leaves

A leaf will usually have a data subset containing many class labels. Choose the class that has the most items in the subset. Alternatively, label the leaf with the number it contains in each class for a probabilistic “soft” classification.

#### Random Forest

<img src="CS%20361.assets/image-20221125145134527.png" alt="image-20221125145134527" style="zoom:50%;" />

#### SVM problem formulation

<img src="CS%20361.assets/image-20221125145533885.png" alt="image-20221125145533885" style="zoom:50%;" />

<img src="CS%20361.assets/image-20221125145641946.png" alt="image-20221125145641946" style="zoom:50%;" />

The **loss function** can help decide if one boundary is better than others

<img src="CS%20361.assets/image-20221125150054861.png" alt="image-20221125150054861" style="zoom:50%;" />

<img src="CS%20361.assets/image-20221125150247729.png" alt="image-20221125150247729" style="zoom:50%;" />

<img src="CS%20361.assets/image-20221125150347642.png" alt="image-20221125150347642" style="zoom:50%;" />

<img src="CS%20361.assets/image-20221125150401775.png" alt="image-20221125150401775" style="zoom:50%;" />

#### Hinge Loss with Regularization Penalty

We add a penalty on the square magnitude $||a||^2 = a^Ta$ 

Training error cost
$$
S(a,b) = [\frac{1}{N} \sum_{i=1}^N\max(0,1-y_i(a^Tx_i+n))] +\lambda(\frac{a^Ta}{2})
$$
The regularization parameter $\lambda$ trade off between these two objectives.

WE compute the decision boundary by minimize loss function $S(a,b)$

#### Convex set and convex function

If a set is convex, any line connecting two points in the set is completely included in the set.

A convex function: the area above the curve is convex

#### SGD

It is a way to find the min of S(a,b)

![image-20221125154725736](CS%20361.assets/image-20221125154725736.png)

<img src="CS%20361.assets/image-20221125154843117.png" alt="image-20221125154843117" style="zoom:50%;" />

## Naïve Bayes classifier

<img src="CS%20361.assets/image-20221125155240557.png" alt="image-20221125155240557" style="zoom:50%;" />

<img src="CS%20361.assets/image-20221125155406653.png" alt="image-20221125155406653" style="zoom:50%;" />
